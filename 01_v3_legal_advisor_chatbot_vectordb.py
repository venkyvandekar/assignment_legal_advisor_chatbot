# -*- coding: utf-8 -*-
"""Copy of legal_advisor_chatbot_vectordb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iFhn5geyqcjIZO_BrncDdQWS0vgns-4Y

# 1. Installing and Importing Necessary Libraries
"""

!pip install langchain-openai
!pip install langchain-community
!pip install openai

!pip install langchain_text_splitters
!pip install pypdf
# !pip uninstall pinecone-client langchain
!pip install pinecone -q
!pip install langchain-pinecone

from langchain_openai import OpenAIEmbeddings # importing embedding model
import pinecone # importing our vector db

from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
import os

"""#2. Chunking

##2.1 Mounting Drive
"""

# 1. mount google drive click on Files>Mount Drive or below is alternate method
from google.colab import drive
drive.mount(r'/content/drive')

"""##2.2 Chunker/Splitter"""

# creating text splitter or chunker
splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=20)

"""##2.3 Website URL Chunks"""

# below are the multiple url for various law and acts related articles
website_links=['https://www.barcouncilofindia.org/info/rules-on-an-advocates-duty-towards-the-court',
             'https://www.barcouncilofindia.org/info/rules-on-an-advocates-duty-towards-the-client',
             'https://www.freelaw.in/legalarticles/Code-of-Ethics-for-Lawyers-in-India-Key-Principles-and-Guidelines',
             'https://www.adanirealty.com/blogs/real-estate-laws-acts-and-regulations-in-india-old-and-new-property-rules?srsltid=AfmBOoqavan5BbUAHSibNBDxCCAW5kzn4O0xVh2xeInPzwfS_j7IWPyz',
             'https://www.adanirealty.com/blogs/maharashtra-rera-maharera-all-you-need-to-know-before-buying-a-house',
             'https://www.adanirealty.com/blogs/check-rera-gujarat-gujrera-registered-projects-details-before-you-buy-a-house',
             'https://www.adanirealty.com/blogs/hrera-haryana-rera-all-you-need-to-know-before-buying-a-home',
             'https://indialegallive.com/legal/18-laws-and-rights-every-indian-should-know/',
             'https://www.toprankers.com/important-laws-that-every-one-should-know?srsltid=AfmBOors-7gSg0E5sK2Iz5vKgs0EZdfbEJcjw1UOgjFAKXlmeU1o2USG',
             'https://blog.ipleaders.in/what-is-a-patent-law-in-india/',
             'https://indiankanoon.org/doc/92819410/',
             'https://indiankanoon.org/doc/180352354/',
             'https://indiankanoon.org/doc/100527417/',
             'https://byjus.com/free-ias-prep/important-articles-in-constitution-india/',
             'https://byjus.com/free-ias-prep/important-acts-in-india/'
             ]

website_documents=WebBaseLoader(website_links).load() # this is processed documents
website_chunks=splitter.split_documents(website_documents) # these are chunks
print(len(website_chunks)) # printing length of chunks

"""##2.4 PDF Chunks"""

pdf_path=r'/content/drive/MyDrive/legal_chatbot_assignment_google_drive_data/pdf_files'
pdf_chunks=[]
# PyPDFLoader loader cannot handle bulk processing hence we do one by one using for loop and then extend in final list
for i in os.listdir(pdf_path):
  if i.endswith('.pdf'):
      print(i)
      i_path=os.path.join(pdf_path,i)
      print(i_path,'\n')
      pdf_documents=PyPDFLoader(i_path).load() # processing documents one by one
      pdf_documents_chunks=splitter.split_documents(pdf_documents) # chunking documents one by one
      pdf_chunks.extend(pdf_documents_chunks) # adding the chunks in a final file

print(len(pdf_chunks))

"""##2.5 Clubbing Webiste Chunks and PDF Chunks"""

total_chunks=[]
total_chunks.extend(website_chunks) # we are extending the list if we add we will get list within a list
total_chunks.extend(pdf_chunks)
print(len(total_chunks))

"""# 3. Setting Up Our Pineconce VectorStore Index

##3.1 Creating PineCone Index
"""

# accessing the pinecone api key saved in google drive
pinecone_api_key = st.secrets.get("PINECONE_API_KEY", os.environ.get("PINECONE_API_KEY"))

with open(pinecone_api_key_path,'r') as file:
  pinecone_api_key=file.read().strip()

print(pinecone_api_key)

# importing pinecone libraries
from pinecone import Pinecone
from pinecone import ServerlessSpec

# initializing the pinceone
pc=Pinecone(api_key=pinecone_api_key)

# creating index
index_name='legal-advisor-chatbot-index'

if index_name not in pc.list_indexes().names():
  pc.create_index(
        name=index_name,
        dimension=3072,
        metric='cosine',
        spec=ServerlessSpec(cloud='aws',region='us-east-1')
  )

# connecting to the index
index=pc.Index(index_name)

"""##3.2 Embedding Model"""

# getting the openai_api_key which is saved in google drive
openai_api_key = st.secrets.get("OPENAI_API_KEY", os.environ.get("OPENAI_API_KEY"))

with open(openai_api_key_path,'r') as file:
  openai_api_key=file.read().strip()

print(openai_api_key)
# creating our embedding model
# embedding_model=OpenAIEmbeddings(model='text-embedding-ada-002',api_key=openai_api_key)
embedding_model=OpenAIEmbeddings(model='text-embedding-3-large',api_key=openai_api_key)

"""##3.3 Langchian Pinecone Integration"""

from langchain_pinecone import PineconeVectorStore # this is langchian compatible vector store

# creating langchian compatible vector store
vectorstore=PineconeVectorStore(index=index, embedding=embedding_model,text_key='text')

vectorstore.add_documents(total_chunks)

# pc.delete_index(index_name) ## incase we do mistake in creating index we have to delete it and again re create it

















































































